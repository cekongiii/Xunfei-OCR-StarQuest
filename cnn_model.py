import tensorflow as tf
from tensorflow.keras import layers, models

# 1. åŠ è½½æ•°æ® (æ”¹æˆäº†è½»é‡çº§ MNIST)
def load_data():
    print("â³ æ­£åœ¨åŠ è½½è½»é‡çº§ MNIST æ•°æ®é›† (æ— éœ€ä¸‹è½½)...")
    # Keras è‡ªå¸¦æ•°æ®ï¼Œåªæœ‰ 11MBï¼Œç¬é—´å®Œæˆ
    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
    
    # è½¬æ¢ä¸º tf.data.Dataset å¯¹è±¡ï¼Œæ–¹ä¾¿åç»­æµæ°´çº¿å¤„ç†
    # æ­¤æ—¶ x_train å½¢çŠ¶æ˜¯ (60000, 28, 28)ï¼Œè¿˜æ²¡æœ‰é€šé“ç»´åº¦
    train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))
    test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))
    
    return train_ds, test_ds

# 2. å®šä¹‰æ¨¡å‹ (è¾“å‡ºæ”¹ä¸º 10 ç±»)
def create_model():
    model = models.Sequential([
        # æ˜¾å¼å®šä¹‰è¾“å…¥å±‚ (28å®½, 28é«˜, 1é€šé“)
        layers.Input(shape=(28, 28, 1)),
        
        # å·ç§¯å±‚æå–ç‰¹å¾
        layers.Conv2D(32, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        
        # å±•å¹³å¹¶å…¨è¿æ¥
        layers.Flatten(),
        layers.Dense(64, activation='relu'),
        
        # ã€å…³é”®ä¿®æ”¹ã€‘MNIST åªæœ‰æ•°å­— 0-9ï¼Œæ‰€ä»¥è¾“å‡ºå±‚æ˜¯ 10 ä¸ªèŠ‚ç‚¹
        layers.Dense(10, activation='softmax') 
    ])
    
    model.compile(optimizer='adam',
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])
    return model

# 3. è®­ç»ƒé€»è¾‘ (å¢åŠ äº† expand_dims å¤„ç†ç»´åº¦)
def train_model(model, train_ds, test_ds):
    # é¢„å¤„ç†å‡½æ•°
    def preprocess(image, label):
        # MNIST æ•°æ®åŸå§‹å½¢çŠ¶æ˜¯ (28, 28)ï¼ŒCNN éœ€è¦ (28, 28, 1)
        # æ‰€ä»¥å¿…é¡»å¢åŠ ä¸€ä¸ªç»´åº¦ (expand_dims)
        image = tf.expand_dims(image, axis=-1)
        # å½’ä¸€åŒ–åˆ° 0-1 ä¹‹é—´
        image = tf.cast(image, tf.float32) / 255.0
        return image, label

    # æ„å»ºæ•°æ®æµæ°´çº¿ï¼šæ‰“ä¹± -> åˆ†æ‰¹ -> é¢„å–
    # buffer_size=10000 è¡¨ç¤ºæ‰“ä¹±çš„ç¨‹åº¦
    train_ds = train_ds.map(preprocess).shuffle(10000).batch(32).prefetch(tf.data.AUTOTUNE)
    test_ds = test_ds.map(preprocess).batch(32).prefetch(tf.data.AUTOTUNE)

    print("ğŸš€ å¼€å§‹è®­ç»ƒæ•°å­—è¯†åˆ«æ¨¡å‹ (å…± 5 è½®)...")
    # å¼€å§‹è®­ç»ƒ
    model.fit(train_ds, epochs=5, validation_data=test_ds)
    
    # ä¿å­˜æ¨¡å‹
    model.save('my_ocr_model.h5')
    print("ğŸ’¾ æ¨¡å‹å·²ä¿å­˜ä¸º my_ocr_model.h5")

# 4. ä¸»ç¨‹åº
if __name__ == "__main__":
    train_ds, test_ds = load_data()
    model = create_model()
    train_model(model, train_ds, test_ds)